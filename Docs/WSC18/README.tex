% Created 2018-12-18 Tue 12:25
\documentclass[11pt]{article}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{fixltx2e}
\usepackage{graphicx}
\usepackage{longtable}
\usepackage{float}
\usepackage{wrapfig}
\usepackage{rotating}
\usepackage[normalem]{ulem}
\usepackage{amsmath}
\usepackage{textcomp}
\usepackage{marvosym}
\usepackage{wasysym}
\usepackage{amssymb}
\usepackage{hyperref}
\tolerance=1000
\author{Kvc}
\date{\today}
\title{README}
\hypersetup{
  pdfkeywords={},
  pdfsubject={},
  pdfcreator={Emacs 24.5.1 (Org mode 8.2.10)}}
\begin{document}

\maketitle
\tableofcontents

This directory contains the experiment setup and results from the 
winter simulation conference paper "Just in time Parallel Simulation.

The data structure evaluation is contained in data$_{\text{structure}}$$_{\text{eval}}$ directory. 
The results reported in the paper were evaluated on a 2017 Macbook pro 
with a 2.3 GHz Intel Core i5-7360U processor (while plugged in). 
Additionally new results have been added from a Intel Core i7-4790 CPU @ 3.6GHz x8

\section{Installation}
\label{sec-1}
You need python 2 and pypy and the dev packages for them.
Installation from source is how I did it in osx and in Ubuntu I installed with
apt-get install pypy python pypy-dev python-dev

The Beta version of Pypy is better and the
 Beta version of LuaJit is MUCH 
better but you can still see the trends in the Linux chart.


\section{Tests and explainations}
\label{sec-2}
\subsection{Test 1 static priorities}
\label{sec-2-1}
In this test we add 1,000,000 items to the priority queue with increasing priorities.
i.e. Loop (i=0; i < 1000000; ++i) \{enqueue(i,NULL)\}
then loop again to dequeue all events


\subsection{Test 2 random priorities}
\label{sec-2-2}
In this test we add 1,000,000 items to the priority queue with random priorities.
i.e. Loop (i=0; i < 1000000; ++i) \{enqueue(rand(0,1000000),NULL)\}
then loop again to dequeue all events



\subsection{Test 2 random priorities}
\label{sec-2-3}
In this test we add 1,000,000 items to the priority queue with random priorities.
i.e. 
while (\#enqueued < 1000000)\{
Loop (i=0; i < rand(1000); ++i) \{enqueue(rand(0,1000000),NULL)\}
Loop (i=0; i < rand(1000); ++i) \{dequeue()\}
\}
so the total number of elements in the queue are always dynamic 
but the total enqueue/dequeue number is equal to 1000000.

\subsection{number of runs:}
\label{sec-2-4}
I believe that the average of the fastest runs should be used. 
You can run it for example 10 times with 100 executions and 
take the best of the 100 for each 10 and then take the average of the 10.
To restate: take the fastest execution of 100 runs. 
Do this 10 times and then average the 10. 
My intuition is that this method should remove some of the OS uncertainties.
It has occured to me to note 
that the dynamic compiler DOES need some time to 'warmup'


\section{List of Directories:}
\label{sec-3}
To interpret the results: three lines are printed, each line corresponds to test 1,2,3

Change the numbers and repeats to be smaller if you want it to run faster

\subsection{heap - cpythons heapq module}
\label{sec-3-1}
\begin{itemize}
\item CPython: run with \verb~python ./test_heap.py~
\item Pypy: run with  \verb~pypy ./test_heap.py~
\end{itemize}
\subsection{pyheap - python heap}
\label{sec-3-2}
\begin{itemize}
\item CPython: run with \verb~python ./test_heap.py~
\item Pypy: run with  \verb~pypy ./test_heap.py~
\end{itemize}
The pypy pyheap and heapq should be identical because there is no c compiled heapq in the pypy Jit compiler
\subsection{cheap cffi - cffi API mode}
\label{sec-3-3}
\begin{itemize}
\item CPython: compile module with \verb~python heap_inter.py~ run with \verb~python test_heap.py~
\item Pypy: compile module with \verb~pypy heap_inter.py~ run with \verb~pypy test_heap.py~
\end{itemize}
\subsection{cheap ctype}
\label{sec-3-4}
run make and then 
\begin{itemize}
\item CPython: run with \verb~python ./test_heap.py~
\item Pypy: run with  \verb~pypy ./test_heap.py~
\end{itemize}
\subsection{calendarQ}
\label{sec-3-5}
\begin{itemize}
\item CPython: run with \verb~python ./test_heap.py~
\item Pypy: run with  \verb~pypy ./test_heap.py~
\end{itemize}
the problem with the calendar queue is that it is not space 
optimized so the growth/shrink operations take a long time

\subsection{fibheap - native python code - fibonacci heap}
\label{sec-3-6}
\begin{itemize}
\item CPython: run with \verb~python ./test_heap.py~
\item Pypy: run with  \verb~pypy ./test_heap.py~
\end{itemize}

\subsection{Lua - holds all the simian for lua}
\label{sec-3-7}
\begin{itemize}
\item \verb~Luajit test_heap.lua~
\end{itemize}
Each test is commented out and can just be ran manually 
with an external timer like `time` each test here can also
run it like 10 times so i just script via command line to 
run 10 times, average, and divide by 10 

\subsection{cheap c}
\label{sec-3-8}
Again comment which function you want to run
\begin{itemize}
\item Compile with \verb~gcc -Ofast cheap.c -o cheap~
\item or try to compile with other options??
\item run with \verb~./cheap~
\end{itemize}
\subsection{misc}
\label{sec-3-9}
There are 4 configurations of 2-tiered queues. binary and fibonacci. 
 I ran these with a bunch of configurations of the 
LA-PDES benchmark but there was no speedup compared to a single tier queues



\section{Results}
\label{sec-4}

\subsection{Results Macbook Pro (OSX)}
\label{sec-4-1}

\begin{center}
\begin{tabular}{lrrrl}
Implemenation & Static priorities & Random Priorities & Interleaved Operations & \\
\hline
CPython C Heapq & 3.434 & 9.167 & 3.720 & \\
CPython Python Heapq & 8.417 & 13.261 & 7.789 & \\
CPython CFFI (API mode) & 3.541 & 5.974 & 5.227 & \\
CPython Ctypes & 6.349 & 12.4 & 10.2 & \\
\hline
Pypy heapq (default module) & 0.855 & 2.246 & 0.371 & \\
Pypy Python priority Queue & 0.873 & 2.243 & 0.371 & \\
Pypy CFFI & 1.903 & 2.832 & 1.660 & \\
Pypy Ctypes & 18.4 & 18.5 & 18.5 & \\
Pypy Calendar Queue (python) & 1.049 & 3.158 & 15.371 & \\
Pypy Fibonocci Heap (python) & 1.353 & 9.947 & 1.259 & \\
\hline
LuaJIT Pure Lua & 0.933 & 2.271 & 0.574 & \\
Pure C code & 0.850 & 1.588 & 0.663 & \\
\hline
\end{tabular}
\end{center}


\subsection{Results in Linux machine}
\label{sec-4-2}
I only did 10/10 for number of runs so it didnt take all day, If you run it 100/100 it takes like a week.


\begin{center}
\begin{tabular}{lrrr}
Implemenation & Static Priorities & Random Priorities & Interleaved Operations\\
\hline
CPython C Heapq & 2.215 & 6.398 & 2.302\\
CPython Python Heapq & 4.696 & 8.743 & 4.213\\
CPython CFFI (API mode) & 2.502 & 4.061 & 2.789\\
CPython CTypes & 2.475 & 3.35 & 3.421\\
\hline
Pypy heapq & 0.814 & 2.694 & 0.366\\
Pypy python priority Q & 0.774 & 2.526 & 0.366\\
Pypy CFFI & 1.673 & 2.684 & 1.418\\
Pypy Ctypes & 6.96 & 7.183 & 7.112\\
Pypy Calendar Queue & 1.203 & 3.796 & 15.136\\
Pypy Fibonocci heap & 1.196 & 10.844 & 1.365\\
\hline
LuaJit Pure Lua & 0.968 & 2.533 & 0.872\\
C code & 0.986 & 1.759 & 0.8334\\
\end{tabular}
\end{center}
% Emacs 24.5.1 (Org mode 8.2.10)
\end{document}
